"""Advanced memory management and garbage collection optimization."""

import gc
import sys
import time
import threading
import weakref
import psutil
import logging
import asyncio
import tracemalloc
from typing import Dict, List, Any, Optional, Callable, Set, Union, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, deque
from contextlib import contextmanager, asynccontextmanager
from functools import wraps
import resource
import mmap
import os
from pathlib import Path

logger = logging.getLogger(__name__)


@dataclass
class MemorySnapshot:
    """Memory usage snapshot at a point in time."""
    timestamp: datetime
    total_memory_mb: float
    available_memory_mb: float
    process_memory_mb: float
    gc_stats: Dict[int, Dict[str, int]]
    top_allocations: List[Dict[str, Any]]
    object_counts: Dict[str, int]
    heap_size_mb: float
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "timestamp": self.timestamp.isoformat(),
            "total_memory_mb": self.total_memory_mb,
            "available_memory_mb": self.available_memory_mb,
            "process_memory_mb": self.process_memory_mb,
            "memory_usage_percent": (self.process_memory_mb / self.total_memory_mb) * 100,
            "gc_stats": self.gc_stats,
            "top_allocations": self.top_allocations,
            "object_counts": self.object_counts,
            "heap_size_mb": self.heap_size_mb
        }


@dataclass
class MemoryLeak:
    """Detected memory leak information."""
    detection_time: datetime
    object_type: str
    growth_rate_mb_per_minute: float
    current_size_mb: float
    sample_objects: List[str]
    stack_traces: List[str]
    confidence: float
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "detection_time": self.detection_time.isoformat(),
            "object_type": self.object_type,
            "growth_rate_mb_per_minute": self.growth_rate_mb_per_minute,
            "current_size_mb": self.current_size_mb,
            "sample_objects": self.sample_objects,
            "stack_traces": self.stack_traces,
            "confidence": self.confidence
        }


class MemoryPool:
    """Custom memory pool for object reuse."""
    
    def __init__(self, object_factory: Callable, max_size: int = 1000):
        self.object_factory = object_factory
        self.max_size = max_size
        self.pool: deque = deque()
        self.created_count = 0
        self.reused_count = 0
        self._lock = threading.Lock()
    
    def acquire(self):
        """Acquire an object from the pool or create new one."""
        with self._lock:
            if self.pool:
                obj = self.pool.popleft()
                self.reused_count += 1
                return obj
            else:
                obj = self.object_factory()
                self.created_count += 1
                return obj
    
    def release(self, obj):
        """Release an object back to the pool."""
        with self._lock:
            if len(self.pool) < self.max_size:
                # Reset object state if it has a reset method
                if hasattr(obj, 'reset'):
                    obj.reset()
                self.pool.append(obj)
    
    def get_stats(self) -> Dict[str, Any]:
        """Get pool statistics."""
        with self._lock:
            return {
                "pool_size": len(self.pool),
                "max_size": self.max_size,
                "created_count": self.created_count,
                "reused_count": self.reused_count,
                "reuse_rate": self.reused_count / (self.created_count + self.reused_count) if (self.created_count + self.reused_count) > 0 else 0
            }
    
    def clear(self):
        """Clear the pool."""
        with self._lock:
            self.pool.clear()


class WeakReferenceTracker:
    """Track object lifecycle using weak references."""
    
    def __init__(self):
        self.tracked_objects: Dict[str, Set[weakref.ref]] = defaultdict(set)
        self.creation_times: Dict[int, float] = {}
        self.destruction_callbacks: Dict[str, List[Callable]] = defaultdict(list)
    
    def track_object(self, obj: Any, category: str = "default"):
        """Track an object's lifecycle."""
        obj_id = id(obj)
        self.creation_times[obj_id] = time.time()
        
        def cleanup_callback(ref):
            self.tracked_objects[category].discard(ref)
            creation_time = self.creation_times.pop(obj_id, None)
            
            # Call destruction callbacks
            for callback in self.destruction_callbacks[category]:\n                try:\n                    callback(obj_id, creation_time)\n                except Exception as e:\n                    logger.error(f\"Error in destruction callback: {e}\")\n        \n        ref = weakref.ref(obj, cleanup_callback)\n        self.tracked_objects[category].add(ref)\n        return ref\n    \n    def add_destruction_callback(self, category: str, callback: Callable):\n        \"\"\"Add callback to be called when objects in category are destroyed.\"\"\"\n        self.destruction_callbacks[category].append(callback)\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get tracking statistics.\"\"\"\n        stats = {}\n        for category, refs in self.tracked_objects.items():\n            # Clean up dead references\n            alive_refs = {ref for ref in refs if ref() is not None}\n            self.tracked_objects[category] = alive_refs\n            \n            stats[category] = {\n                \"alive_objects\": len(alive_refs),\n                \"avg_age_seconds\": 0\n            }\n            \n            # Calculate average age\n            if alive_refs:\n                current_time = time.time()\n                ages = []\n                for ref in alive_refs:\n                    obj = ref()\n                    if obj is not None:\n                        creation_time = self.creation_times.get(id(obj))\n                        if creation_time:\n                            ages.append(current_time - creation_time)\n                \n                if ages:\n                    stats[category][\"avg_age_seconds\"] = sum(ages) / len(ages)\n        \n        return stats\n\n\nclass GarbageCollectionOptimizer:\n    \"\"\"Intelligent garbage collection optimization.\"\"\"\n    \n    def __init__(self):\n        self.original_thresholds = gc.get_threshold()\n        self.gc_stats_history: deque = deque(maxlen=100)\n        self.performance_metrics: Dict[str, deque] = {\n            \"collection_time\": deque(maxlen=50),\n            \"objects_collected\": deque(maxlen=50),\n            \"memory_freed_mb\": deque(maxlen=50)\n        }\n        \n        # Optimization settings\n        self.auto_tune_enabled = True\n        self.performance_threshold = 0.1  # seconds\n        self.memory_pressure_threshold = 0.8  # 80% memory usage\n        \n        # Current settings\n        self.current_thresholds = list(self.original_thresholds)\n        self.last_tuning_time = time.time()\n        self.tuning_interval = 300  # 5 minutes\n        \n    def enable_debug_stats(self):\n        \"\"\"Enable garbage collection debug statistics.\"\"\"\n        gc.set_debug(gc.DEBUG_STATS)\n    \n    def disable_debug_stats(self):\n        \"\"\"Disable garbage collection debug statistics.\"\"\"\n        gc.set_debug(0)\n    \n    def force_collection(self, generation: Optional[int] = None) -> Dict[str, Any]:\n        \"\"\"Force garbage collection and measure performance.\"\"\"\n        start_time = time.time()\n        start_memory = psutil.Process().memory_info().rss / 1024 / 1024\n        \n        if generation is None:\n            collected = gc.collect()\n        else:\n            collected = gc.collect(generation)\n        \n        end_time = time.time()\n        end_memory = psutil.Process().memory_info().rss / 1024 / 1024\n        \n        collection_time = end_time - start_time\n        memory_freed = start_memory - end_memory\n        \n        # Record metrics\n        self.performance_metrics[\"collection_time\"].append(collection_time)\n        self.performance_metrics[\"objects_collected\"].append(collected)\n        self.performance_metrics[\"memory_freed_mb\"].append(memory_freed)\n        \n        stats = {\n            \"collection_time\": collection_time,\n            \"objects_collected\": collected,\n            \"memory_freed_mb\": memory_freed,\n            \"gc_counts\": gc.get_count(),\n            \"gc_stats\": gc.get_stats()\n        }\n        \n        logger.debug(f\"GC forced: {collected} objects collected in {collection_time:.3f}s, {memory_freed:.2f}MB freed\")\n        return stats\n    \n    def optimize_thresholds(self, memory_usage_percent: float, avg_collection_time: float):\n        \"\"\"Optimize GC thresholds based on current performance.\"\"\"\n        if not self.auto_tune_enabled:\n            return\n        \n        current_time = time.time()\n        if current_time - self.last_tuning_time < self.tuning_interval:\n            return\n        \n        gen0, gen1, gen2 = self.current_thresholds\n        \n        # Adjust based on memory pressure\n        if memory_usage_percent > self.memory_pressure_threshold:\n            # High memory pressure - more aggressive collection\n            gen0 = max(200, int(gen0 * 0.8))\n            gen1 = max(10, int(gen1 * 0.8))\n            gen2 = max(5, int(gen2 * 0.8))\n            logger.info(\"Tuning GC for high memory pressure\")\n        elif memory_usage_percent < 0.5:\n            # Low memory pressure - less aggressive collection\n            gen0 = min(2000, int(gen0 * 1.2))\n            gen1 = min(20, int(gen1 * 1.2))\n            gen2 = min(20, int(gen2 * 1.2))\n            logger.debug(\"Tuning GC for low memory pressure\")\n        \n        # Adjust based on collection time\n        if avg_collection_time > self.performance_threshold:\n            # Collections taking too long - reduce frequency\n            gen0 = min(2000, int(gen0 * 1.1))\n            gen1 = min(20, int(gen1 * 1.1))\n            logger.info(\"Tuning GC to reduce collection frequency\")\n        \n        # Apply new thresholds if they changed significantly\n        if abs(gen0 - self.current_thresholds[0]) > 50 or \\\n           abs(gen1 - self.current_thresholds[1]) > 2 or \\\n           abs(gen2 - self.current_thresholds[2]) > 2:\n            \n            self.current_thresholds = [gen0, gen1, gen2]\n            gc.set_threshold(gen0, gen1, gen2)\n            \n            logger.info(f\"GC thresholds updated: {self.current_thresholds}\")\n        \n        self.last_tuning_time = current_time\n    \n    def get_performance_stats(self) -> Dict[str, Any]:\n        \"\"\"Get GC performance statistics.\"\"\"\n        stats = {\n            \"current_thresholds\": self.current_thresholds,\n            \"original_thresholds\": list(self.original_thresholds),\n            \"auto_tune_enabled\": self.auto_tune_enabled,\n            \"gc_counts\": gc.get_count(),\n            \"gc_stats\": gc.get_stats(),\n        }\n        \n        # Add performance metrics\n        for metric_name, values in self.performance_metrics.items():\n            if values:\n                stats[f\"avg_{metric_name}\"] = sum(values) / len(values)\n                stats[f\"max_{metric_name}\"] = max(values)\n                stats[f\"min_{metric_name}\"] = min(values)\n        \n        return stats\n    \n    def reset_to_defaults(self):\n        \"\"\"Reset GC thresholds to Python defaults.\"\"\"\n        gc.set_threshold(*self.original_thresholds)\n        self.current_thresholds = list(self.original_thresholds)\n        logger.info(\"GC thresholds reset to defaults\")\n\n\nclass MemoryLeakDetector:\n    \"\"\"Advanced memory leak detection system.\"\"\"\n    \n    def __init__(self, sampling_interval: int = 60):\n        self.sampling_interval = sampling_interval\n        self.snapshots: deque = deque(maxlen=100)  # Keep last 100 snapshots\n        self.detected_leaks: List[MemoryLeak] = []\n        self.monitoring_task: Optional[asyncio.Task] = None\n        self.monitoring_enabled = False\n        \n        # Leak detection thresholds\n        self.growth_threshold_mb = 10.0  # MB per hour\n        self.confidence_threshold = 0.7\n        self.min_samples_for_detection = 10\n        \n    async def start_monitoring(self):\n        \"\"\"Start continuous memory leak monitoring.\"\"\"\n        if self.monitoring_task and not self.monitoring_task.done():\n            return\n        \n        # Enable tracemalloc for detailed tracking\n        if not tracemalloc.is_tracing():\n            tracemalloc.start()\n        \n        self.monitoring_enabled = True\n        self.monitoring_task = asyncio.create_task(self._monitoring_loop())\n        logger.info(\"Memory leak monitoring started\")\n    \n    async def stop_monitoring(self):\n        \"\"\"Stop memory leak monitoring.\"\"\"\n        self.monitoring_enabled = False\n        if self.monitoring_task:\n            self.monitoring_task.cancel()\n            try:\n                await self.monitoring_task\n            except asyncio.CancelledError:\n                pass\n        logger.info(\"Memory leak monitoring stopped\")\n    \n    async def _monitoring_loop(self):\n        \"\"\"Background monitoring loop.\"\"\"\n        while self.monitoring_enabled:\n            try:\n                await self._take_snapshot()\n                \n                # Analyze for leaks if we have enough samples\n                if len(self.snapshots) >= self.min_samples_for_detection:\n                    await self._analyze_for_leaks()\n                \n                await asyncio.sleep(self.sampling_interval)\n                \n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Memory monitoring error: {e}\")\n                await asyncio.sleep(self.sampling_interval)\n    \n    async def _take_snapshot(self):\n        \"\"\"Take a memory usage snapshot.\"\"\"\n        # System memory info\n        system_memory = psutil.virtual_memory()\n        process = psutil.Process()\n        process_memory = process.memory_info().rss / 1024 / 1024\n        \n        # Tracemalloc info\n        top_allocations = []\n        object_counts = {}\n        \n        if tracemalloc.is_tracing():\n            snapshot = tracemalloc.take_snapshot()\n            top_stats = snapshot.statistics('lineno')[:20]\n            \n            for stat in top_stats:\n                top_allocations.append({\n                    \"filename\": stat.traceback.format()[0] if stat.traceback.format() else \"unknown\",\n                    \"size_mb\": stat.size / 1024 / 1024,\n                    \"count\": stat.count\n                })\n        \n        # Object counts by type\n        for obj in gc.get_objects():\n            obj_type = type(obj).__name__\n            object_counts[obj_type] = object_counts.get(obj_type, 0) + 1\n        \n        # GC statistics\n        gc_stats = {}\n        for i, stats in enumerate(gc.get_stats()):\n            gc_stats[i] = stats\n        \n        snapshot = MemorySnapshot(\n            timestamp=datetime.now(),\n            total_memory_mb=system_memory.total / 1024 / 1024,\n            available_memory_mb=system_memory.available / 1024 / 1024,\n            process_memory_mb=process_memory,\n            gc_stats=gc_stats,\n            top_allocations=top_allocations,\n            object_counts=object_counts,\n            heap_size_mb=sys.getsizeof(gc.get_objects()) / 1024 / 1024\n        )\n        \n        self.snapshots.append(snapshot)\n    \n    async def _analyze_for_leaks(self):\n        \"\"\"Analyze snapshots for potential memory leaks.\"\"\"\n        if len(self.snapshots) < self.min_samples_for_detection:\n            return\n        \n        recent_snapshots = list(self.snapshots)[-self.min_samples_for_detection:]\n        \n        # Analyze overall memory growth\n        memory_values = [s.process_memory_mb for s in recent_snapshots]\n        time_span_hours = (recent_snapshots[-1].timestamp - recent_snapshots[0].timestamp).total_seconds() / 3600\n        \n        if time_span_hours > 0:\n            growth_rate = (memory_values[-1] - memory_values[0]) / time_span_hours\n            \n            if growth_rate > self.growth_threshold_mb:\n                # Potential memory leak detected\n                await self._investigate_leak(recent_snapshots, growth_rate)\n    \n    async def _investigate_leak(self, snapshots: List[MemorySnapshot], growth_rate: float):\n        \"\"\"Investigate potential memory leak in detail.\"\"\"\n        # Analyze object type growth\n        object_growth = {}\n        \n        for obj_type in snapshots[0].object_counts.keys():\n            initial_count = snapshots[0].object_counts.get(obj_type, 0)\n            final_count = snapshots[-1].object_counts.get(obj_type, 0)\n            growth = final_count - initial_count\n            \n            if growth > 100:  # Significant growth\n                object_growth[obj_type] = growth\n        \n        # Find top growing object types\n        top_growing = sorted(object_growth.items(), key=lambda x: x[1], reverse=True)[:5]\n        \n        for obj_type, growth in top_growing:\n            # Calculate confidence based on consistency of growth\n            type_counts = [s.object_counts.get(obj_type, 0) for s in snapshots]\n            \n            # Simple linear regression to check growth consistency\n            if len(type_counts) >= 5:\n                import statistics\n                \n                # Check if growth is consistent (not just a one-time spike)\n                recent_trend = type_counts[-5:]\n                if all(recent_trend[i] <= recent_trend[i+1] for i in range(len(recent_trend)-1)):\n                    confidence = min(0.9, growth / 1000)  # Higher confidence for more growth\n                    \n                    if confidence > self.confidence_threshold:\n                        # Get sample stack traces\n                        stack_traces = []\n                        sample_objects = []\n                        \n                        # This would require more advanced introspection\n                        # For now, use placeholder data\n                        stack_traces.append(\"Stack trace analysis requires detailed profiling\")\n                        sample_objects.append(f\"Sample {obj_type} objects\")\n                        \n                        leak = MemoryLeak(\n                            detection_time=datetime.now(),\n                            object_type=obj_type,\n                            growth_rate_mb_per_minute=growth_rate / 60,\n                            current_size_mb=growth * self._estimate_object_size(obj_type) / 1024 / 1024,\n                            sample_objects=sample_objects,\n                            stack_traces=stack_traces,\n                            confidence=confidence\n                        )\n                        \n                        self.detected_leaks.append(leak)\n                        logger.warning(f\"Memory leak detected: {obj_type} growing at {growth} objects/hour\")\n    \n    def _estimate_object_size(self, obj_type: str) -> int:\n        \"\"\"Estimate average size of objects by type.\"\"\"\n        # Rough estimates in bytes\n        size_estimates = {\n            \"dict\": 296,\n            \"list\": 88,\n            \"str\": 50,\n            \"tuple\": 72,\n            \"set\": 232,\n            \"function\": 136,\n            \"method\": 64,\n            \"type\": 1056,\n            \"module\": 552\n        }\n        \n        return size_estimates.get(obj_type, 100)  # Default 100 bytes\n    \n    def get_detected_leaks(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all detected memory leaks.\"\"\"\n        return [leak.to_dict() for leak in self.detected_leaks]\n    \n    def get_memory_trend(self, hours: int = 24) -> Dict[str, Any]:\n        \"\"\"Get memory usage trend over specified hours.\"\"\"\n        if not self.snapshots:\n            return {\"error\": \"No memory snapshots available\"}\n        \n        cutoff_time = datetime.now() - timedelta(hours=hours)\n        recent_snapshots = [s for s in self.snapshots if s.timestamp >= cutoff_time]\n        \n        if len(recent_snapshots) < 2:\n            return {\"error\": \"Insufficient data for trend analysis\"}\n        \n        memory_values = [s.process_memory_mb for s in recent_snapshots]\n        timestamps = [s.timestamp for s in recent_snapshots]\n        \n        return {\n            \"start_memory_mb\": memory_values[0],\n            \"end_memory_mb\": memory_values[-1],\n            \"memory_change_mb\": memory_values[-1] - memory_values[0],\n            \"avg_memory_mb\": sum(memory_values) / len(memory_values),\n            \"max_memory_mb\": max(memory_values),\n            \"min_memory_mb\": min(memory_values),\n            \"time_span_hours\": (timestamps[-1] - timestamps[0]).total_seconds() / 3600,\n            \"growth_rate_mb_per_hour\": (memory_values[-1] - memory_values[0]) / ((timestamps[-1] - timestamps[0]).total_seconds() / 3600) if timestamps[-1] != timestamps[0] else 0,\n            \"data_points\": len(recent_snapshots)\n        }\n\n\nclass MemoryManager:\n    \"\"\"Comprehensive memory management system.\"\"\"\n    \n    def __init__(self):\n        self.gc_optimizer = GarbageCollectionOptimizer()\n        self.leak_detector = MemoryLeakDetector()\n        self.weak_ref_tracker = WeakReferenceTracker()\n        self.memory_pools: Dict[str, MemoryPool] = {}\n        \n        # Configuration\n        self.enable_auto_gc_tuning = True\n        self.enable_leak_detection = True\n        self.memory_pressure_threshold = 0.85  # 85%\n        self.emergency_cleanup_threshold = 0.95  # 95%\n        \n        # Monitoring\n        self.monitoring_task: Optional[asyncio.Task] = None\n        self.cleanup_callbacks: List[Callable] = []\n        \n    async def initialize(self):\n        \"\"\"Initialize memory management system.\"\"\"\n        if self.enable_leak_detection:\n            await self.leak_detector.start_monitoring()\n        \n        # Start background monitoring\n        self.monitoring_task = asyncio.create_task(self._memory_monitoring_loop())\n        \n        logger.info(\"Memory management system initialized\")\n    \n    def create_memory_pool(self, name: str, object_factory: Callable, max_size: int = 1000) -> MemoryPool:\n        \"\"\"Create a named memory pool for object reuse.\"\"\"\n        pool = MemoryPool(object_factory, max_size)\n        self.memory_pools[name] = pool\n        logger.info(f\"Created memory pool '{name}' with max size {max_size}\")\n        return pool\n    \n    def get_memory_pool(self, name: str) -> Optional[MemoryPool]:\n        \"\"\"Get a memory pool by name.\"\"\"\n        return self.memory_pools.get(name)\n    \n    def track_object(self, obj: Any, category: str = \"default\") -> weakref.ref:\n        \"\"\"Track an object's lifecycle.\"\"\"\n        return self.weak_ref_tracker.track_object(obj, category)\n    \n    def add_cleanup_callback(self, callback: Callable):\n        \"\"\"Add callback to be called during memory cleanup.\"\"\"\n        self.cleanup_callbacks.append(callback)\n    \n    async def _memory_monitoring_loop(self):\n        \"\"\"Background memory monitoring and optimization.\"\"\"\n        while True:\n            try:\n                await asyncio.sleep(60)  # Check every minute\n                await self._check_memory_pressure()\n                \n                if self.enable_auto_gc_tuning:\n                    await self._optimize_garbage_collection()\n                    \n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Memory monitoring error: {e}\")\n    \n    async def _check_memory_pressure(self):\n        \"\"\"Check system memory pressure and take action if needed.\"\"\"\n        memory_info = psutil.virtual_memory()\n        memory_percent = memory_info.percent / 100.0\n        \n        if memory_percent > self.emergency_cleanup_threshold:\n            logger.critical(f\"Emergency memory cleanup triggered: {memory_percent:.1%} usage\")\n            await self._emergency_cleanup()\n            \n        elif memory_percent > self.memory_pressure_threshold:\n            logger.warning(f\"High memory pressure detected: {memory_percent:.1%} usage\")\n            await self._perform_cleanup()\n    \n    async def _optimize_garbage_collection(self):\n        \"\"\"Optimize garbage collection based on current conditions.\"\"\"\n        memory_info = psutil.virtual_memory()\n        memory_percent = memory_info.percent / 100.0\n        \n        # Get average collection time\n        perf_stats = self.gc_optimizer.get_performance_stats()\n        avg_collection_time = perf_stats.get(\"avg_collection_time\", 0)\n        \n        self.gc_optimizer.optimize_thresholds(memory_percent, avg_collection_time)\n    \n    async def _perform_cleanup(self):\n        \"\"\"Perform memory cleanup operations.\"\"\"\n        logger.info(\"Performing memory cleanup\")\n        \n        # Call registered cleanup callbacks\n        for callback in self.cleanup_callbacks:\n            try:\n                if asyncio.iscoroutinefunction(callback):\n                    await callback()\n                else:\n                    callback()\n            except Exception as e:\n                logger.error(f\"Error in cleanup callback: {e}\")\n        \n        # Clear memory pools\n        for pool in self.memory_pools.values():\n            pool.clear()\n        \n        # Force garbage collection\n        gc_stats = self.gc_optimizer.force_collection()\n        logger.info(f\"Cleanup completed: {gc_stats['objects_collected']} objects collected, {gc_stats['memory_freed_mb']:.2f}MB freed\")\n    \n    async def _emergency_cleanup(self):\n        \"\"\"Perform emergency memory cleanup.\"\"\"\n        logger.critical(\"Performing emergency memory cleanup\")\n        \n        # More aggressive cleanup\n        await self._perform_cleanup()\n        \n        # Force full GC cycle\n        for generation in range(3):\n            self.gc_optimizer.force_collection(generation)\n        \n        # Clear internal caches\n        import sys\n        if hasattr(sys, 'intern'):\n            # Clear interned strings (Python 3+)\n            pass  # sys.intern cache can't be directly cleared\n        \n        # Clear line cache\n        import linecache\n        linecache.clearcache()\n        \n        logger.critical(\"Emergency cleanup completed\")\n    \n    @contextmanager\n    def memory_context(self, cleanup_on_exit: bool = True):\n        \"\"\"Context manager that performs cleanup on exit.\"\"\"\n        start_memory = psutil.Process().memory_info().rss / 1024 / 1024\n        \n        try:\n            yield\n        finally:\n            if cleanup_on_exit:\n                # Force garbage collection\n                collected = gc.collect()\n                \n                end_memory = psutil.Process().memory_info().rss / 1024 / 1024\n                memory_change = end_memory - start_memory\n                \n                logger.debug(f\"Memory context exit: {collected} objects collected, memory change: {memory_change:.2f}MB\")\n    \n    def get_comprehensive_stats(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive memory management statistics.\"\"\"\n        # System memory info\n        system_memory = psutil.virtual_memory()\n        process = psutil.Process()\n        process_memory = process.memory_info()\n        \n        return {\n            \"system_memory\": {\n                \"total_gb\": system_memory.total / 1024 / 1024 / 1024,\n                \"available_gb\": system_memory.available / 1024 / 1024 / 1024,\n                \"used_percent\": system_memory.percent,\n                \"pressure_level\": self._get_pressure_level(system_memory.percent / 100.0)\n            },\n            \"process_memory\": {\n                \"rss_mb\": process_memory.rss / 1024 / 1024,\n                \"vms_mb\": process_memory.vms / 1024 / 1024,\n                \"peak_mb\": getattr(process_memory, 'peak_wset', 0) / 1024 / 1024 if hasattr(process_memory, 'peak_wset') else 0\n            },\n            \"garbage_collection\": self.gc_optimizer.get_performance_stats(),\n            \"memory_pools\": {\n                name: pool.get_stats() for name, pool in self.memory_pools.items()\n            },\n            \"object_tracking\": self.weak_ref_tracker.get_stats(),\n            \"detected_leaks\": self.leak_detector.get_detected_leaks(),\n            \"memory_trend\": self.leak_detector.get_memory_trend(hours=4),\n            \"configuration\": {\n                \"enable_auto_gc_tuning\": self.enable_auto_gc_tuning,\n                \"enable_leak_detection\": self.enable_leak_detection,\n                \"memory_pressure_threshold\": self.memory_pressure_threshold,\n                \"emergency_cleanup_threshold\": self.emergency_cleanup_threshold\n            }\n        }\n    \n    def _get_pressure_level(self, usage_percent: float) -> str:\n        \"\"\"Get memory pressure level description.\"\"\"\n        if usage_percent > self.emergency_cleanup_threshold:\n            return \"critical\"\n        elif usage_percent > self.memory_pressure_threshold:\n            return \"high\"\n        elif usage_percent > 0.7:\n            return \"moderate\"\n        else:\n            return \"low\"\n    \n    def get_optimization_recommendations(self) -> List[Dict[str, str]]:\n        \"\"\"Get memory optimization recommendations.\"\"\"\n        recommendations = []\n        \n        # Analyze current state\n        stats = self.get_comprehensive_stats()\n        \n        # System memory recommendations\n        if stats[\"system_memory\"][\"used_percent\"] > 90:\n            recommendations.append({\n                \"type\": \"critical\",\n                \"title\": \"Critical memory usage\",\n                \"description\": f\"System memory usage is {stats['system_memory']['used_percent']:.1f}%\",\n                \"action\": \"Increase system memory or reduce application memory usage\"\n            })\n        \n        # GC recommendations\n        gc_stats = stats[\"garbage_collection\"]\n        if gc_stats.get(\"avg_collection_time\", 0) > 0.1:\n            recommendations.append({\n                \"type\": \"performance\",\n                \"title\": \"Slow garbage collection\",\n                \"description\": f\"Average GC time is {gc_stats['avg_collection_time']:.3f}s\",\n                \"action\": \"Consider adjusting GC thresholds or reducing object creation\"\n            })\n        \n        # Memory pool recommendations\n        for pool_name, pool_stats in stats[\"memory_pools\"].items():\n            if pool_stats[\"reuse_rate\"] < 0.5:\n                recommendations.append({\n                    \"type\": \"optimization\",\n                    \"title\": f\"Low reuse rate in pool '{pool_name}'\",\n                    \"description\": f\"Pool reuse rate is {pool_stats['reuse_rate']:.1%}\",\n                    \"action\": \"Review object pooling strategy or pool size\"\n                })\n        \n        # Leak detection recommendations\n        if stats[\"detected_leaks\"]:\n            recommendations.append({\n                \"type\": \"critical\",\n                \"title\": \"Memory leaks detected\",\n                \"description\": f\"Found {len(stats['detected_leaks'])} potential memory leaks\",\n                \"action\": \"Investigate and fix memory leaks\"\n            })\n        \n        return recommendations\n    \n    async def shutdown(self):\n        \"\"\"Shutdown memory management system.\"\"\"\n        logger.info(\"Shutting down memory management system\")\n        \n        if self.monitoring_task:\n            self.monitoring_task.cancel()\n            try:\n                await self.monitoring_task\n            except asyncio.CancelledError:\n                pass\n        \n        if self.enable_leak_detection:\n            await self.leak_detector.stop_monitoring()\n        \n        # Clear all pools\n        for pool in self.memory_pools.values():\n            pool.clear()\n        \n        logger.info(\"Memory management system shutdown complete\")\n\n\n# Global memory manager instance\nmemory_manager = MemoryManager()\n\n\n# Convenience decorators and utilities\ndef memory_optimized(cleanup_on_exit: bool = True):\n    \"\"\"Decorator to optimize memory usage for a function.\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @wraps(func)\n        async def async_wrapper(*args, **kwargs):\n            with memory_manager.memory_context(cleanup_on_exit):\n                return await func(*args, **kwargs)\n        \n        @wraps(func)\n        def sync_wrapper(*args, **kwargs):\n            with memory_manager.memory_context(cleanup_on_exit):\n                return func(*args, **kwargs)\n        \n        if asyncio.iscoroutinefunction(func):\n            return async_wrapper\n        else:\n            return sync_wrapper\n    \n    return decorator\n\n\n@contextmanager\ndef track_memory_usage(label: str = \"operation\"):\n    \"\"\"Context manager to track memory usage of a code block.\"\"\"\n    start_memory = psutil.Process().memory_info().rss / 1024 / 1024\n    start_time = time.time()\n    \n    try:\n        yield\n    finally:\n        end_memory = psutil.Process().memory_info().rss / 1024 / 1024\n        end_time = time.time()\n        \n        memory_delta = end_memory - start_memory\n        duration = end_time - start_time\n        \n        logger.info(f\"Memory tracking [{label}]: {memory_delta:+.2f}MB change in {duration:.3f}s\")\n\n\nclass MemoryEfficientQueue:\n    \"\"\"Memory-efficient queue implementation using memory pools.\"\"\"\n    \n    def __init__(self, name: str = \"default\"):\n        self.name = name\n        self.items = deque()\n        self._pool = memory_manager.get_memory_pool(f\"queue_{name}\")\n        \n        if not self._pool:\n            # Create pool for queue items if it doesn't exist\n            self._pool = memory_manager.create_memory_pool(\n                f\"queue_{name}\",\n                lambda: {\"data\": None, \"metadata\": {}},\n                max_size=1000\n            )\n    \n    def put(self, item: Any, metadata: Dict[str, Any] = None):\n        \"\"\"Add item to queue using memory pool.\"\"\"\n        queue_item = self._pool.acquire()\n        queue_item[\"data\"] = item\n        queue_item[\"metadata\"] = metadata or {}\n        queue_item[\"timestamp\"] = time.time()\n        \n        self.items.append(queue_item)\n    \n    def get(self) -> Optional[Any]:\n        \"\"\"Get item from queue and return it to pool.\"\"\"\n        if not self.items:\n            return None\n        \n        queue_item = self.items.popleft()\n        data = queue_item[\"data\"]\n        \n        # Return item to pool\n        queue_item[\"data\"] = None\n        queue_item[\"metadata\"] = {}\n        self._pool.release(queue_item)\n        \n        return data\n    \n    def size(self) -> int:\n        \"\"\"Get queue size.\"\"\"\n        return len(self.items)\n    \n    def clear(self):\n        \"\"\"Clear the queue and return all items to pool.\"\"\"\n        while self.items:\n            item = self.items.popleft()\n            item[\"data\"] = None\n            item[\"metadata\"] = {}\n            self._pool.release(item)"